{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7eceb6233753e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from photometry_analysis import load_filtered_behavior_data\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from glm_hmm_analysis import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3519cfd5",
   "metadata": {},
   "source": [
    "Load a filtered behavior dataframe to be used in downstream functions. Saves computational power and increases speed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14047f1e9de6b681",
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_df = load_filtered_behavior_data(\"MatchingPennies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f6e42a",
   "metadata": {},
   "source": [
    "For selected subjid, for all sessions or specified session plot probabilities of being in each state across all trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e31011610e03462",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_state_probabilities(\"JOA-M-0020\", session_date=None, behavior_df=behavior_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec0a3a0",
   "metadata": {},
   "source": [
    "For selected subjid or \"All\", plot the average state occupation across all sessions (not only photometry sessions). smooth_window selects number of sessions the state occupation is smoothed. Average only plotted for sessions with > 3 animals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302c406d",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_state_occupation(behavior_df=behavior_df, subjid=\"All\", smooth_window=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f22338",
   "metadata": {},
   "source": [
    "Plot photometry data split by state. Option to split by current trial outcome (win_loss=True and condition='current_trial') or previous trial outcome (condition=\"previous_trial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9540ecc44075e1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_behavioral_states(\"JOA-M-0020\", win_loss=True, condition=\"current_trial\", behavior_df=behavior_df)\n",
    "#Either plots win and loss trials (\"current trial\"), or previous win and loss trials (\"previous trial\"), or just states without sepearation (win_loss=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dffc55b",
   "metadata": {},
   "source": [
    "Similar to function in dopamine_analysis_pipeline.ipynb, but split by state. Either take specific subjid or \"All\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a965ae66d2498be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_previous_outcome_effect_by_state(\"JOA-M-0024\", behavior_df=behavior_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80584e7d",
   "metadata": {},
   "source": [
    "Analysis of p(Switch), but split by state. Select signal window and condition (loss or win trials). For more detailed description, see corresponding function in dopamine_analysis_pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e6bb70317a1ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_signal_quartiles_by_state(\"JOA-M-0026\", signal_window='late_post', condition='win', plot_verification=True, behavior_df=behavior_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d72cd90aa096ff",
   "metadata": {},
   "source": [
    "Count consecutive loss streaks. \n",
    "This counts only consecutive loss streaks within a state. If the loss streak is not resolved in the state (no win in this state, but state shift), these loss streaks are NOT counted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d94904cd5a1d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_loss_streaks_by_state(\"JOA-M-0020\", split_biased=False, behavior_df=behavior_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666313d5",
   "metadata": {},
   "source": [
    "Plots photometry of last loss trial (plot_trial=\"loss\") or first win trial (\"win\") after different length loss streaks. Option to only plot 1 consecutive loss vs 3+ (only_1_3=True). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ccb333ab33530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_loss_streaks_by_state_photometry(\"JOA-M-0020\", only_1_3=True, behavior_df=behavior_df, plot_trial=\"win\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737b33ca",
   "metadata": {},
   "source": [
    "Counts the number of trials between 1 state being above 0.8 and the next (different) state being above 0.8. Used to visualize how long state transitions normally last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a53fb936bac5697",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_state_transitions(\"JOA-M-0022\", window_size=30, min_stable_trials=2, split_bias=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c49e22e",
   "metadata": {},
   "source": [
    "Count the number of trials for each current reward rate. Biased state split based on reward rate into high and low halves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dab3d8ae49a5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_reward_rate_distribution_by_state(\"JOA-M-0020\", window_size=30, behavior_df=behavior_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484502d5",
   "metadata": {},
   "source": [
    "Plot reward expectation and reward history signal for both states. Either for single subjid or \"All\". Option to split bias state based on reward rate into biased_high and biased_low. Can define window size to calculate current reward rate with which biased state is split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ba143a",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_reward_rate_state_win_loss(\"All\", window_size=30, behavior_df=behavior_df, split_biased=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b1e2db",
   "metadata": {},
   "source": [
    "Analyze photometry for stay or switch behavior and reward outcome, either for single subject or \"All\". Option to split by state (state=True). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a55842",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_stay_switch_photometry(\"All\", behavior_df=behavior_df, state=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30973e52",
   "metadata": {},
   "source": [
    "Plot photometry signal for early, middle, and late trials for one state period. Also plots photometry signal for transition trials (between 2 states being >0.8). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e8f505",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_state_period_photometry(\"All\", behavior_df=behavior_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "matching_pennies",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
